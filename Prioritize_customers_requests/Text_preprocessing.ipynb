{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Очистка от стоп слов, смайликов, токенизация, Леммитизация, Обработка сущностей"
      ],
      "metadata": {
        "id": "Jn-cDQn1SWjH"
      },
      "id": "Jn-cDQn1SWjH"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# === EMOJI UNICODE PATTERN ===\n",
        "EMOJI_PATTERN = re.compile(\n",
        "    \"[\"\n",
        "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "    \"\\U0001F700-\\U0001F77F\"\n",
        "    \"\\U0001F780-\\U0001F7FF\"\n",
        "    \"\\U0001F800-\\U0001F8FF\"\n",
        "    \"\\U0001F900-\\U0001F9FF\"\n",
        "    \"\\U0001FA00-\\U0001FAFF\"\n",
        "    \"\\u2600-\\u26FF\"          # misc symbols\n",
        "    \"\\u2700-\\u27BF\"\n",
        "    \"]+\",\n",
        "    flags=re.UNICODE\n",
        ")\n",
        "\n",
        "# === TEXT EMOJIS MAPPING ===\n",
        "TEXT_EMOJI_MAP = {\n",
        "    r\":\\)\": \"<EMOJI_POS>\",\n",
        "    r\"=\\)\": \"<EMOJI_POS>\",\n",
        "    r\":d\": \"<EMOJI_POS>\",\n",
        "    r\";\\)\": \"<EMOJI_NEUTRAL>\",\n",
        "    r\":\\(\": \"<EMOJI_NEG>\",\n",
        "    r\":-\\(\": \"<EMOJI_NEG>\",\n",
        "    r\":/\": \"<EMOJI_NEG>\",\n",
        "}\n",
        "\n",
        "# === OPTIONAL: simple slang normalization ===\n",
        "SLANG_MAP = {\n",
        "    r\"\\bpls\\b\": \"please\",\n",
        "    r\"\\bplz\\b\": \"please\",\n",
        "    r\"\\basap\\b\": \"as soon as possible\",\n",
        "    r\"\\burg\\b\": \"urgent\",\n",
        "    r\"\\bu\\b\": \"you\",\n",
        "    r\"\\br\\b\": \"are\",\n",
        "    r\"\\btho\\b\": \"though\",\n",
        "}\n",
        "\n",
        "def preprocess_text(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # --- Remove HTML ---\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text(\" \")\n",
        "\n",
        "    # --- Remove emojis ---\n",
        "    text = EMOJI_PATTERN.sub(\" \", text)\n",
        "\n",
        "\n",
        "    # --- Replace emails ---\n",
        "    text = re.sub(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b', ' <EMAIL> ', text)\n",
        "\n",
        "    # --- Replace URLs ---\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' <URL> ', text)\n",
        "\n",
        "    # --- Replace IPs ---\n",
        "    text = re.sub(r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b', ' <IP> ', text)\n",
        "\n",
        "    # --- Replace Ticket / IDs ---\n",
        "    text = re.sub(r'\\b[A-Z]{2,}-?\\d{3,}\\b', ' <ID> ', text)\n",
        "\n",
        "    # --- Replace nicknames @username ---\n",
        "    text = re.sub(r'@\\w+', ' <USER> ', text)\n",
        "\n",
        "    # --- Replace dates ---\n",
        "    text = re.sub(r'\\b\\d{4}[-/]\\d{2}[-/]\\d{2}\\b', ' <DATE> ', text)\n",
        "    text = re.sub(r'\\b\\d{2}[-/]\\d{2}[-/]\\d{4}\\b', ' <DATE> ', text)\n",
        "\n",
        "    # --- Replace times ---\n",
        "    text = re.sub(r'\\b\\d{1,2}:\\d{2}\\b', ' <TIME> ', text)\n",
        "\n",
        "    # --- Replace text-based emojis ---\n",
        "    for pattern, replacement in TEXT_EMOJI_MAP.items():\n",
        "        text = re.sub(pattern, replacement, text)\n",
        "\n",
        "    # --- Replace numbers (after removing $) ---\n",
        "    text = text.replace(\"$\", \"\")\n",
        "    text = re.sub(r'\\b\\d+(\\.\\d+)?\\b', ' <NUM> ', text)\n",
        "\n",
        "    # --- Remove non-latin characters (optional) ---\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "\n",
        "    # letter + number OR number + letter\n",
        "    text = re.sub(r'(?<=\\D)(?=\\d)|(?<=\\d)(?=\\D)', ' ', text)\n",
        "\n",
        "    # --- Lowercase ---\n",
        "    text = text.lower()\n",
        "\n",
        "    # --- Slang normalization ---\n",
        "    for pattern, replacement in SLANG_MAP.items():\n",
        "        text = re.sub(pattern, replacement, text)\n",
        "\n",
        "    # --- Remove repeated punctuation ---\n",
        "    text = re.sub(r'([!?.,]){2,}', r'\\1', text)\n",
        "\n",
        "    # --- Remove extra whitespace ---\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # --- Handle hashtags: remove # but keep word ---\n",
        "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "Em0FOw5Kh4He"
      },
      "id": "Em0FOw5Kh4He",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/ready_sample.xlsx\")\n",
        "# 'text_column' — имя столбца с исходными текстами\n",
        "\n",
        "df[\"text\"] = df[\"text\"].apply(preprocess_text)\n",
        "\n",
        "# --- Дополнительные числовые признаки ---\n",
        "#df[\"text_length\"] = df[\"clean_text\"].str.len()\n",
        "#df[\"word_count\"] = df[\"clean_text\"].str.split().str.len()\n",
        "#df[\"num_exclamations\"] = df[\"text\"].str.count(\"!\")\n",
        "#df[\"has_urgent\"] = df[\"clean_text\"].str.contains(r'\\burgent|as soon as possible|critical\\b').astype(int)\n"
      ],
      "metadata": {
        "id": "qqodofoqh66y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28b75ed-3db2-400d-ff16-8326d0214164"
      },
      "id": "qqodofoqh66y",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2527253945.py:49: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
            "\n",
            "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
            "\n",
            "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
            "\n",
            "    from bs4 import MarkupResemblesLocatorWarning\n",
            "    import warnings\n",
            "\n",
            "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
            "    \n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text(\" \")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel('Clean_text.xlsx', index=False)"
      ],
      "metadata": {
        "id": "pEB1y17oce6v"
      },
      "id": "pEB1y17oce6v",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zjIq249ibRJL"
      },
      "id": "zjIq249ibRJL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}